import argparse
import datetime
import json
import logging
import os
import pdb
import sys
import time

import requests

import subtitle_utils 
import paths_and_headers # paths and headers that are shared across the central/utils folder 

headers = paths_and_headers.headers

data_path = paths_and_headers.data_path

logger = subtitle_utils.setup_logging("download_subtitles")

SRTS_JSON_FILENAME = paths_and_headers.api_info_filename

LANGUAGE_SRT_FILENAME = paths_and_headers.language_srt_map

# HELP: Is there a better way to organize the below import of settings?
PROJECT_PATH = os.path.dirname(os.path.realpath(__file__))
sys.path = [PROJECT_PATH, os.path.join(PROJECT_PATH, "../../"), os.path.join(
    PROJECT_PATH, "../python-packages/")] + sys.path

import settings

download_path = settings.LOCALE_PATHS[0]  # ka-lite/locale/


class LanguageCodeDoesNotExist(Exception):

    def __str__(value):
        return "The language code specified does not have any available subtitles for download."


def update_language_srt_map():
    """Update the language_srt_map from the api_info_map"""

    # Create file if first time being run
    language_srt_filepath = data_path + LANGUAGE_SRT_FILENAME
    if not subtitle_utils.file_already_exists(language_srt_filepath):
        with open(language_srt_filepath, 'w') as outfile:
            json.dump({}, outfile)

    language_srt_map = json.loads(open(language_srt_filepath).read())
    api_info_map = json.loads(open(data_path + SRTS_JSON_FILENAME).read())

    for youtube_id, content in api_info_map.items():
        lang_list = content.get("language_codes") or []
        for code in lang_list:
            # create language section if it doesn't exist
            language_srt_map.get(code)
            if not language_srt_map.get(code):
                logger.info("Creating language section '%s'" % code)
                language_srt_map[code] = {}
            # create empty entry for video entry if it doesn't exist
            if not language_srt_map[code].get(youtube_id):
                logger.info("Creating entry in '%s' for YouTube video: '%s'" % (
                    code, youtube_id))
                language_srt_map[code][youtube_id] = {
                    "downloaded": False,
                    "api_response": "",
                    "last_attempt": "",
                    "last_success": "",
                }

    logger.info("Writing updates to %s" % language_srt_filepath)
    with open(language_srt_filepath, 'wb') as fp:
            json.dump(language_srt_map, fp)


def prepare_for_download(args):
    """Download subtitles specified by command line args"""
    # json generated by download_subtitles.py (this file)
    language_srt_map = json.loads(open(
        data_path + LANGUAGE_SRT_FILENAME).read())

    lang_code = args.language

    # if lang_code specified, do those, if not do all
    if lang_code:
        try:
            vids_in_language = language_srt_map.get(lang_code)
        except:
            raise LanguageCodeDoesNotExist()
        download_if_criteria_met(vids_in_language, args, lang_code)

    else:
        for lang_code, videos in language_srt_map.items():
            download_if_criteria_met(videos, args, lang_code)


def download_if_criteria_met(videos, args, lang_code):
    """Execute download of subtitle if it meets the criteria specified by the command line args"""

    redo_requested = args.redo
    response_code = args.response_code
    date_specified = subtitle_utils.convert_date_input(args.date_since_attempt)

    for youtube_id, entry in videos.items():
        last_attempt = entry.get("last_attempt")
        api_response = entry.get("api_response")
        previously_downloaded = entry.get("downloaded")

        # HELP: I feel like this set of logic gates could be more efficient or
        # easier to read
        date_test_passed = False
        response_code_test = False

        # pdb.set_trace()
        if date_specified:
            if not last_attempt or datetime.datetime.strptime(last_attempt, '%Y-%m-%d') < date_specified:
                date_test_passed = True
            else:
                logger.info(
                    "Last attempt more recent than specified date. Moving on.")
        # response code must be specified, so it must exist
        if response_code == "all" or response_code == api_response:
            response_code_test = True
        else:
            logger.info(
                "API response doesn't match specified HTTP status code. Moving on.")

        # HELP: not feeling to good stylistically for having this extra block 
        download_it = False
        if date_specified and date_test_passed and response_code_test:
            download_it = True
        elif not date_specified and response_code_test:
            download_it = True

        if download_it:
            if not previously_downloaded or redo_requested:
                logger.info("Attempting to download subtitle for lang: %s and YouTube ID: %s" % (lang_code, youtube_id))
                response = download_subtitle(youtube_id, lang_code, format="srt")
                time_of_attempt = unicode(datetime.datetime.now().date())
                if response == "client-error" or response == "server-error":
                    logger.info("Updating JSON file to record %s." % response)
                    update_json(
                        youtube_id, lang_code, previously_downloaded, response, time_of_attempt)
                else:
                    # pdb.set_trace()
                    dirpath = download_path + lang_code + "/subtitles/"
                    filename = youtube_id + ".srt"
                    fullpath = dirpath + filename
                    logger.info("Writing file to %s" % fullpath)

                    if not os.path.exists(dirpath):
                        os.makedirs(dirpath)

                    with open(fullpath, 'w') as fp:
                        fp.write(response.encode('UTF-8'))

                    logger.info("Updating JSON file to record xe.")
                    update_json(youtube_id, lang_code, True, "success", time_of_attempt)
            else:
                logger.info(
                    "Already downloaded. To redownload, run again with -R.")


def download_subtitle(youtube_id, language, format="srt"):
    """Return subtitles for YouTube ID in language specified. Return False if they do not exist. Update local JSON accordingly."""

    api_info_map = json.loads(open(data_path + SRTS_JSON_FILENAME).read())
    # get amara id
    amara_code = api_info_map.get(youtube_id).get("amara_code")

    # make request
    base_url = "https://amara.org/api2/partners/videos"
    # HELP: do we ever call for the json format? otherwise this top block can go
    # if format == "json":
    #     return subtitle_utils.make_request("%s/%s/languages/%s/subtitles/" % (
    #         base_url, amara_code, language))
    if format == "srt":
        r = subtitle_utils.make_request("%s/%s/languages/%s/subtitles/?format=srt" % (
            base_url, amara_code, language))
        if r:
            # return the subtitle text, replacing empty subtitle lines with
            # spaces to make the FLV player happy
            try:
                response = (r.text or "").replace("\n\n\n", "\n   \n\n").replace("\r\n\r\n\r\n", "\r\n   \r\n\r\n")
            except: 
                response = r 
            return response
    return False


def update_json(youtube_id, lang_code, downloaded, api_response, time_of_attempt):
    """Update language_srt_map to reflect download status"""
    #Open JSON file
    filepath = data_path + LANGUAGE_SRT_FILENAME
    language_srt_map = json.loads(open(filepath).read())

    # create updated entry
    entry = language_srt_map[lang_code][youtube_id] 
    entry["downloaded"] = downloaded
    entry["api_response"] = api_response
    entry["last_attempt"] = time_of_attempt
    if api_response == "success":
        entry["last_success"] = time_of_attempt

    # update full-size JSON with new information
    language_srt_map[lang_code][youtube_id].update(entry)

    # write it to file
    logger.info("File updated.")
    json_file = open(filepath, "w+")
    json_file.write(json.dumps(language_srt_map))
    json_file.close()


def create_parser():
    # parses command line args
    parser = argparse.ArgumentParser()
    parser.add_argument('-l', '--language', default=None,
                        help="Specify a particular language code to download subtitles for. Can be used with -R to update previously downloaded subtitles.")
    parser.add_argument('-R', '--redo', action='store_true',
                        help="Re-download previously downloaded subtitles to refresh the repo. Can be used with -l. Default behavior is to not re-download subtitles we already have.")
    parser.add_argument('-r', '--response_code', default=None,
                        help="Which api-response code to recheck. Can be combined with -d. USAGE: '-r all', '-r client-error', or '-r server-error'. This MUST be set.")
    parser.add_argument('-d', '--date_since_attempt', default=None,
                        help="Setting a date flag will update only those entries which have not been attempted since that date. Can be combined with -r. This could potentially be useful for updating old subtitles. USAGE: '-d MM/DD/YYYY'.")
    parser.add_argument('-U', '--update', action='store_true',
                        help="Use this after updating the mappings with generate_subtitle_map. Will override anything else. It will update the JSON file used to store information about which subtitles have actually been downloaded.")
    return parser


if __name__ == '__main__':
    parser = create_parser()
    args = parser.parse_args()
    if args.update:
        update_language_srt_map()
    elif args.response_code:
        prepare_for_download(args)
    else:
        logger.info(
            "Invalid input. Please read the usage instructions more carefully and try again. (P.S. Don't forget to specify a response code.)")
        parser.print_help()
        sys.exit(1)
    logger.info("Process complete.")
    sys.exit(1)
